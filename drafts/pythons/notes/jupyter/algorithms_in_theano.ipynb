{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "$$ \\bar{y} = wx + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import theano\n",
    "from theano import tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x11195ac18>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1118fb5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X = np.linspace(-1, 1, 101)\n",
    "train_Y = 2 * train_X + 1 + np.random.randn(train_X.size) * 0.33\n",
    "plt.scatter(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = T.scalar(), T.scalar()\n",
    "X.name, Y.name = 'x', 'y'\n",
    "\n",
    "def linear_model(X, w, b):\n",
    "    return X * w + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数： $ C = \\left|\\bar{y} - y \\right|^2 $\n",
    "\n",
    "我们可以使用梯度下降法来迭代参数 w,b 的值，为此，我们将 w 和 b 设成共享变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'((x * w) + b)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = theano.shared(np.asarray(0., dtype=theano.config.floatX))\n",
    "w.name = 'w'\n",
    "b = theano.shared(np.asarray(0., dtype=theano.config.floatX))\n",
    "b.name = 'b'\n",
    "\n",
    "Y_bar = linear_model(X, w, b)\n",
    "theano.pp(Y_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = T.mean(T.sqr(Y_bar - Y))\n",
    "grads = T.grad(cost=cost, wrt=[w, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "updates = [[w, w - grads[0] * lr],\n",
    "           [b, b - grads[1] * lr]]\n",
    "\n",
    "train_model = theano.function(inputs=[X,Y],\n",
    "                              outputs=cost,\n",
    "                              updates=updates,\n",
    "                              allow_input_downcast=True)\n",
    "\n",
    "for i in range(100):\n",
    "    for x, y in zip(train_X, train_Y):\n",
    "        train_model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0960926268346407\n",
      "0.9833693080320884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11199a2b0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nd4sMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111a9d128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(w.get_value()) \n",
    "print(b.get_value())\n",
    "\n",
    "plt.scatter(train_X, train_Y)\n",
    "plt.plot(train_X, w.get_value() * train_X + b.get_value(), 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "$$ s(x) = \\frac{1}{1 + e^{-x}} = \\frac{1 + tanh\\left(\\frac{x}{2}\\right)}{2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = np.random\n",
    "\n",
    "# 数据大小和规模\n",
    "N = 400\n",
    "feats = 784\n",
    "\n",
    "# D = (X, Y)\n",
    "D = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.matrix('x')\n",
    "y = T.vector('y')\n",
    "\n",
    "# 要更新的变量：\n",
    "w = theano.shared(rng.randn(feats), name='w')\n",
    "b = theano.shared(0., name='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = 1 / (1 + T.exp(-T.dot(x, w) - b))\n",
    "prediction = h > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = - T.mean(y * T.log(h) + (1 - y) * T.log(1 - h)) + 0.01 * T.sum(w ** 2)  # 正则项，防止过拟合\n",
    "gw, gb = T.grad(cost, [w, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter     0, error nan\n",
      "iter  1000, error 0.20916386518319272\n",
      "iter  2000, error 0.12385585775631414\n",
      "iter  3000, error 0.12256679622266706\n",
      "iter  4000, error 0.12254240274449477\n",
      "iter  5000, error 0.12254162133721462\n",
      "iter  6000, error 0.12254152989301592\n",
      "iter  7000, error 0.12254151063149532\n",
      "iter  8000, error 0.12254150627087208\n",
      "iter  9000, error 0.12254150527768518\n",
      "iter 10000, error 0.12254150505136419\n"
     ]
    }
   ],
   "source": [
    "train = theano.function(inputs=[x, y],\n",
    "                        outputs=cost,\n",
    "                        updates=[[w, w - 0.1 * gw], [b, b - 0.1 * gb]], \n",
    "                        allow_input_downcast=True)\n",
    "\n",
    "predict = theano.function(inputs=[x],\n",
    "                          outputs=prediction,\n",
    "                          allow_input_downcast=True)\n",
    "\n",
    "for i in range(10001):\n",
    "    err = train(D[0], D[1])\n",
    "    if i % 1000 == 0:\n",
    "        print('iter {0:5d}, error {1}'.format(i, err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False,  True,  True,  True, False, False,\n",
       "        True, False,  True,  True,  True,  True, False, False, False,\n",
       "       False, False,  True, False,  True, False, False, False,  True,\n",
       "       False,  True, False,  True,  True,  True, False, False,  True,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False,  True,  True,  True,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "        True, False,  True, False, False,  True, False,  True,  True,\n",
       "        True, False,  True, False,  True,  True, False, False,  True,\n",
       "        True, False,  True, False, False,  True, False, False,  True,\n",
       "       False, False,  True,  True, False, False,  True, False,  True,\n",
       "       False, False,  True, False, False,  True, False,  True, False,\n",
       "        True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "        True, False, False,  True,  True, False,  True,  True, False,\n",
       "        True, False, False, False, False,  True, False, False,  True,\n",
       "       False,  True,  True, False,  True,  True, False, False, False,\n",
       "       False,  True, False,  True,  True, False, False,  True,  True,\n",
       "        True, False,  True,  True, False,  True, False, False,  True,\n",
       "       False,  True,  True, False,  True, False, False,  True, False,\n",
       "        True,  True,  True,  True, False,  True,  True,  True, False,\n",
       "       False, False, False,  True, False,  True, False,  True, False,\n",
       "        True,  True, False, False,  True, False, False,  True, False,\n",
       "        True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "       False,  True, False, False,  True, False, False, False, False,\n",
       "        True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "        True,  True, False,  True, False, False,  True,  True, False,\n",
       "        True, False,  True, False, False,  True,  True,  True, False,\n",
       "       False,  True,  True, False, False, False, False,  True, False,\n",
       "       False, False,  True,  True, False, False,  True, False, False,\n",
       "        True, False, False, False, False,  True, False,  True, False,\n",
       "       False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "       False, False, False,  True,  True,  True, False,  True,  True,\n",
       "        True, False, False,  True,  True, False, False, False, False,\n",
       "       False,  True, False,  True,  True, False, False,  True,  True,\n",
       "        True, False, False, False, False, False,  True,  True,  True,\n",
       "       False, False,  True,  True, False, False,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "       False,  True,  True, False, False, False,  True, False, False,\n",
       "       False,  True, False, False,  True, False, False,  True, False,\n",
       "       False, False,  True,  True,  True, False, False, False,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "       False,  True, False,  True, False,  True, False,  True, False,\n",
       "       False,  True, False,  True, False, False, False, False,  True,\n",
       "        True,  True,  True, False,  True, False,  True, False,  True,\n",
       "       False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(D[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression\n",
    "\n",
    "[MNIST 数据集](http://yann.lecun.com/exdb/mnist/) 是一个手写数字组成的数据集，现在被当作一个机器学习算法评测的基准数据集。\n",
    "\n",
    "这是一个下载并解压数据的脚本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing download_mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%file download_mnist.py\n",
    "import os\n",
    "import os.path\n",
    "import urllib\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "if not os.path.exists('mnist'):\n",
    "    os.mkdir('mnist')\n",
    "\n",
    "def download_and_gzip(name):\n",
    "    if not os.path.exists(name + '.gz'):\n",
    "        urllib.request.urlretrieve('http://yann.lecun.com/exdb/' + name + '.gz', name + '.gz')\n",
    "    if not os.path.exists(name):\n",
    "        with gzip.open(name + '.gz', 'rb') as f_in, open(name, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "            \n",
    "download_and_gzip('mnist/train-images-idx3-ubyte')\n",
    "download_and_gzip('mnist/train-labels-idx1-ubyte')\n",
    "download_and_gzip('mnist/t10k-images-idx3-ubyte')\n",
    "download_and_gzip('mnist/t10k-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run download_mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing load.py\n"
     ]
    }
   ],
   "source": [
    "%%file load.py\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "datasets_dir = './'\n",
    "\n",
    "def one_hot(x,n):\n",
    "\tif type(x) == list:\n",
    "\t\tx = np.array(x)\n",
    "\tx = x.flatten()\n",
    "\to_h = np.zeros((len(x),n))\n",
    "\to_h[np.arange(len(x)),x] = 1\n",
    "\treturn o_h\n",
    "\n",
    "def mnist(ntrain=60000,ntest=10000,onehot=True):\n",
    "\tdata_dir = os.path.join(datasets_dir,'mnist/')\n",
    "\tfd = open(os.path.join(data_dir,'train-images-idx3-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\ttrX = loaded[16:].reshape((60000,28*28)).astype(float)\n",
    "\n",
    "\tfd = open(os.path.join(data_dir,'train-labels-idx1-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\ttrY = loaded[8:].reshape((60000))\n",
    "\n",
    "\tfd = open(os.path.join(data_dir,'t10k-images-idx3-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\tteX = loaded[16:].reshape((10000,28*28)).astype(float)\n",
    "\n",
    "\tfd = open(os.path.join(data_dir,'t10k-labels-idx1-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\tteY = loaded[8:].reshape((10000))\n",
    "\n",
    "\ttrX = trX/255.\n",
    "\tteX = teX/255.\n",
    "\n",
    "\ttrX = trX[:ntrain]\n",
    "\ttrY = trY[:ntrain]\n",
    "\n",
    "\tteX = teX[:ntest]\n",
    "\tteY = teY[:ntest]\n",
    "\n",
    "\tif onehot:\n",
    "\t\ttrY = one_hot(trY, 10)\n",
    "\t\tteY = one_hot(teY, 10)\n",
    "\telse:\n",
    "\t\ttrY = np.asarray(trY)\n",
    "\t\tteY = np.asarray(teY)\n",
    "\n",
    "\treturn trX,teX,trY,teY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "[ 1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "from load import mnist\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "A = T.matrix()\n",
    "\n",
    "B = T.nnet.softmax(A)\n",
    "\n",
    "test_softmax = theano.function([A], B)\n",
    "\n",
    "a = floatX(np.random.rand(3, 4))\n",
    "\n",
    "b = test_softmax(a)\n",
    "\n",
    "print(b.shape)\n",
    "\n",
    "# 行和\n",
    "print(b.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, w):\n",
    "    return T.nnet.softmax(T.dot(X, w))\n",
    "\n",
    "trX, teX, trY, teY = mnist(onehot=True)\n",
    "\n",
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "w = init_weights((784, 10))\n",
    "\n",
    "py_x = model(X, w)\n",
    "y_pred = T.argmax(py_x, axis=1)\n",
    "\n",
    "# 损失函数为多类的交叉熵，这个在 theano 中也被定义好了：\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(py_x, Y))\n",
    "gradient = T.grad(cost=cost, wrt=w)\n",
    "update = [[w, w - gradient * 0.05]]\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 0.8857\n",
      "001 0.8977\n",
      "002 0.9045\n",
      "003 0.9074\n",
      "004 0.9099\n",
      "005 0.9111\n",
      "006 0.9135\n",
      "007 0.9143\n",
      "008 0.9151\n",
      "009 0.9159\n",
      "010 0.9164\n",
      "011 0.9167\n",
      "012 0.9169\n",
      "013 0.9172\n",
      "014 0.9177\n",
      "015 0.9177\n",
      "016 0.9182\n",
      "017 0.9188\n",
      "018 0.919\n",
      "019 0.919\n",
      "020 0.9197\n",
      "021 0.9199\n",
      "022 0.9199\n",
      "023 0.9204\n",
      "024 0.9205\n",
      "025 0.9205\n",
      "026 0.9209\n",
      "027 0.9211\n",
      "028 0.9211\n",
      "029 0.9214\n",
      "030 0.9213\n",
      "031 0.9216\n",
      "032 0.9215\n",
      "033 0.9218\n",
      "034 0.9219\n",
      "035 0.9218\n",
      "036 0.9217\n",
      "037 0.9218\n",
      "038 0.9221\n",
      "039 0.9222\n",
      "040 0.9223\n",
      "041 0.9225\n",
      "042 0.9225\n",
      "043 0.9225\n",
      "044 0.9224\n",
      "045 0.9225\n",
      "046 0.9225\n",
      "047 0.9224\n",
      "048 0.923\n",
      "049 0.9231\n",
      "050 0.9233\n",
      "051 0.9235\n",
      "052 0.9236\n",
      "053 0.9236\n",
      "054 0.9236\n",
      "055 0.9235\n",
      "056 0.9236\n",
      "057 0.9239\n",
      "058 0.9241\n",
      "059 0.9241\n",
      "060 0.9242\n",
      "061 0.9242\n",
      "062 0.9242\n",
      "063 0.9242\n",
      "064 0.9245\n",
      "065 0.9245\n",
      "066 0.9245\n",
      "067 0.9243\n",
      "068 0.9244\n",
      "069 0.9243\n",
      "070 0.9245\n",
      "071 0.9244\n",
      "072 0.9245\n",
      "073 0.9244\n",
      "074 0.9245\n",
      "075 0.9244\n",
      "076 0.9243\n",
      "077 0.9244\n",
      "078 0.9244\n",
      "079 0.9243\n",
      "080 0.9243\n",
      "081 0.9247\n",
      "082 0.9248\n",
      "083 0.9248\n",
      "084 0.9248\n",
      "085 0.9248\n",
      "086 0.9246\n",
      "087 0.9246\n",
      "088 0.9246\n",
      "089 0.9246\n",
      "090 0.9247\n",
      "091 0.9248\n",
      "092 0.9248\n",
      "093 0.9251\n",
      "094 0.925\n",
      "095 0.925\n",
      "096 0.925\n",
      "097 0.925\n",
      "098 0.9249\n",
      "099 0.9248\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    for start, end in zip(range(0, len(trX), 128), range(128, len(trX), 128)):\n",
    "        cost = train(trX[start:end], trY[start:end])\n",
    "    print(\"{0:03d}\".format(i), np.mean(np.argmax(teY, axis=1) == predict(teX)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN(人工神经网络)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在这里使用一个简单的三层神经网络：输入 - 隐层 - 输出。\n",
    "\n",
    "对于网络的激活函数，隐层用sigmoid函数，输出层用softmax函数，其模型如下：\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "    h &= \\sigma (W_h X) \\\\\n",
    "    o &= \\text{softmax} (W_o h)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, w_h, w_o):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        X: input data\n",
    "        w_h: hidden unit weights\n",
    "        w_o: output unit weights\n",
    "    output:\n",
    "        Y: probability of y given x\n",
    "    \"\"\"\n",
    "    # 隐层\n",
    "    h = T.nnet.sigmoid(T.dot(X, w_h))\n",
    "    # 输出层\n",
    "    pyx = T.nnet.softmax(T.dot(h, w_o))\n",
    "    return pyx\n",
    "\n",
    "def sgd(cost, params, lr=0.05):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        cost: cost function\n",
    "        params: parameters\n",
    "        lr: learning rate\n",
    "    output:\n",
    "        update rules\n",
    "    \"\"\"\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        updates.append([p, p - g * lr])\n",
    "    return updates\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "\n",
    "w_h = init_weights((784, 625))\n",
    "w_o = init_weights((625, 10))\n",
    "\n",
    "py_x = model(X, w_h, w_o)\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(py_x, Y))\n",
    "updates = sgd(cost, [w_h, w_o])\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "\n",
    "trX, teX, trY, teY = mnist(onehot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 0.7079\n",
      "001 0.829\n",
      "002 0.8671\n",
      "003 0.8831\n",
      "004 0.8894\n",
      "005 0.8954\n",
      "006 0.8981\n",
      "007 0.9016\n",
      "008 0.9043\n",
      "009 0.9068\n",
      "010 0.9093\n",
      "011 0.9114\n",
      "012 0.9129\n",
      "013 0.9141\n",
      "014 0.9153\n",
      "015 0.9159\n",
      "016 0.9163\n",
      "017 0.917\n",
      "018 0.9176\n",
      "019 0.9184\n",
      "020 0.9188\n",
      "021 0.919\n",
      "022 0.9195\n",
      "023 0.9197\n",
      "024 0.9204\n",
      "025 0.9208\n",
      "026 0.921\n",
      "027 0.9217\n",
      "028 0.922\n",
      "029 0.9228\n",
      "030 0.9238\n",
      "031 0.9236\n",
      "032 0.9241\n",
      "033 0.9251\n",
      "034 0.9258\n",
      "035 0.9262\n",
      "036 0.9265\n",
      "037 0.9271\n",
      "038 0.9278\n",
      "039 0.9286\n",
      "040 0.9294\n",
      "041 0.9295\n",
      "042 0.9299\n",
      "043 0.93\n",
      "044 0.9304\n",
      "045 0.9307\n",
      "046 0.9317\n",
      "047 0.9322\n",
      "048 0.9331\n",
      "049 0.9334\n",
      "050 0.9338\n",
      "051 0.9352\n",
      "052 0.9359\n",
      "053 0.9366\n",
      "054 0.9374\n",
      "055 0.9379\n",
      "056 0.9385\n",
      "057 0.939\n",
      "058 0.9395\n",
      "059 0.9399\n",
      "060 0.9408\n",
      "061 0.9414\n",
      "062 0.9418\n",
      "063 0.9423\n",
      "064 0.9429\n",
      "065 0.9434\n",
      "066 0.944\n",
      "067 0.9447\n",
      "068 0.9451\n",
      "069 0.9457\n",
      "070 0.9464\n",
      "071 0.9464\n",
      "072 0.947\n",
      "073 0.9474\n",
      "074 0.9478\n",
      "075 0.9485\n",
      "076 0.9488\n",
      "077 0.9491\n",
      "078 0.95\n",
      "079 0.9507\n",
      "080 0.951\n",
      "081 0.9513\n",
      "082 0.9517\n",
      "083 0.952\n",
      "084 0.9527\n",
      "085 0.9535\n",
      "086 0.9536\n",
      "087 0.9543\n",
      "088 0.9545\n",
      "089 0.9548\n",
      "090 0.955\n",
      "091 0.9554\n",
      "092 0.9558\n",
      "093 0.9563\n",
      "094 0.9569\n",
      "095 0.9572\n",
      "096 0.9575\n",
      "097 0.9576\n",
      "098 0.9582\n",
      "099 0.9584\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    for start, end in zip(range(0, len(trX), 128), range(128, len(trX), 128)):\n",
    "        cost = train(trX[start:end], trY[start:end])\n",
    "    print(\"{0:03d}\".format(i), np.mean(np.argmax(teY, axis=1) == predict(teX)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更复杂的神经网络\n",
    "\n",
    "之前我们采用的的激活函数是 sigmoid，现在我们使用 rectify 激活函数。\n",
    "\n",
    "这可以使用 `T.nnet.relu(x, alpha=0)` 来实现，它本质上相当于：`T.switch(x > 0, x, alpha * x)`，而 rectify 函数的定义为：\n",
    "\n",
    "$$\n",
    "\\text{rectify}(x) = \\left\\{\n",
    "\\begin{aligned}\n",
    "x, & \\ x > 0 \\\\\n",
    "0, & \\ x < 0\n",
    "\\end{aligned}\\right.\n",
    "$$\n",
    "\n",
    "之前我们构造的是一个单隐层的神经网络结构，现在我们构造一个双隐层的结构即“输入-隐层1-隐层2-输出”的全连接结构。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& h_1 =  \\text{rectify}(W_{h_1} \\ x) \\\\\n",
    "& h_2 =  \\text{rectify}(W_{h_2} \\ h_1) \\\\\n",
    "& o =  \\text{softmax}(W_o h_2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Theano 自带的 `T.nnet.softmax()` 的 GPU 实现目前似乎有 bug 会导致梯度溢出的问题，因此自定义了 softmax 函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropout(X, prob=0.):\n",
    "    if prob > 0:\n",
    "        X *= srng.binomial(X.shape, p=1-prob, dtype = theano.config.floatX)\n",
    "        X /= 1 - prob\n",
    "    return X\n",
    "\n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
    "\n",
    "def model(X, w_h1, w_h2, w_o, p_drop_input, p_drop_hidden):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        X:             input data\n",
    "        w_h1:          weights input layer to hidden layer 1\n",
    "        w_h2:          weights hidden layer 1 to hidden layer 2\n",
    "        w_o:           weights hidden layer 2 to output layer\n",
    "        p_drop_input:  dropout rate for input layer\n",
    "        p_drop_hidden: dropout rate for hidden layer\n",
    "    output:\n",
    "        h1:    hidden layer 1\n",
    "        h2:    hidden layer 2\n",
    "        py_x:  output layer\n",
    "    \"\"\"\n",
    "    X = dropout(X, p_drop_input)\n",
    "    h1 = T.nnet.relu(T.dot(X, w_h1))\n",
    "    \n",
    "    h1 = dropout(h1, p_drop_hidden)\n",
    "    h2 = T.nnet.relu(T.dot(h1, w_h2))\n",
    "    \n",
    "    h2 = dropout(h2, p_drop_hidden)\n",
    "    py_x = softmax(T.dot(h2, w_o))\n",
    "    return h1, h2, py_x\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "w_h1 = init_weights((784, 625))\n",
    "w_h2 = init_weights((625, 625))\n",
    "w_o = init_weights((625, 10))\n",
    "\n",
    "\n",
    "X = T.matrix()\n",
    "Y = T.matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义更新的规则，之前我们使用的是简单的 SGD，这次我们使用 RMSprop 来更新，其规则为：\n",
    "$$\n",
    "\\begin{align}\n",
    "MS(w, t) &= \\rho MS(w, t-1) + (1-\\rho) \\left(\\left.\\frac{\\partial E}{\\partial w}\\right|_{w(t-1)}\\right)^2 \\\\\n",
    "w(t) &= w(t-1) - \\alpha \\left.\\frac{\\partial E}{\\partial w}\\right|_{w(t-1)} / \\sqrt{MS(w, t)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "srng = RandomStreams()\n",
    "\n",
    "def RMSprop(cost, params, accs, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g, acc in zip(params, grads, accs):\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "# 有 dropout，用来训练\n",
    "noise_h1, noise_h2, noise_py_x = model(X, w_h1, w_h2, w_o, 0.2, 0.5)\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
    "params = [w_h1, w_h2, w_o]\n",
    "accs = [theano.shared(p.get_value() * 0.) for p in params]\n",
    "updates = RMSprop(cost, params, accs, lr=0.001)\n",
    "# 训练函数\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "# 没有 dropout，用来预测\n",
    "h1, h2, py_x = model(X, w_h1, w_h2, w_o, 0., 0.)\n",
    "# 预测的结果\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 001 accuracy: 0.9412\n",
      "iter 002 accuracy: 0.9633\n",
      "iter 003 accuracy: 0.9721\n",
      "iter 004 accuracy: 0.9745\n",
      "iter 005 accuracy: 0.9741\n",
      "iter 006 accuracy: 0.9775\n",
      "iter 007 accuracy: 0.9762\n",
      "iter 008 accuracy: 0.981\n",
      "iter 009 accuracy: 0.9808\n",
      "iter 010 accuracy: 0.9808\n",
      "iter 011 accuracy: 0.9818\n",
      "iter 012 accuracy: 0.9828\n",
      "iter 013 accuracy: 0.9832\n",
      "iter 014 accuracy: 0.9844\n",
      "iter 015 accuracy: 0.984\n",
      "iter 016 accuracy: 0.9826\n",
      "iter 017 accuracy: 0.984\n",
      "iter 018 accuracy: 0.9852\n",
      "iter 019 accuracy: 0.9842\n",
      "iter 020 accuracy: 0.9853\n",
      "iter 021 accuracy: 0.9844\n",
      "iter 022 accuracy: 0.9843\n",
      "iter 023 accuracy: 0.9846\n",
      "iter 024 accuracy: 0.9862\n",
      "iter 025 accuracy: 0.9846\n",
      "iter 026 accuracy: 0.9854\n",
      "iter 027 accuracy: 0.9855\n",
      "iter 028 accuracy: 0.9858\n",
      "iter 029 accuracy: 0.9869\n",
      "iter 030 accuracy: 0.9872\n",
      "iter 031 accuracy: 0.9854\n",
      "iter 032 accuracy: 0.9852\n",
      "iter 033 accuracy: 0.9851\n",
      "iter 034 accuracy: 0.9874\n",
      "iter 035 accuracy: 0.9857\n",
      "iter 036 accuracy: 0.9857\n",
      "iter 037 accuracy: 0.9851\n",
      "iter 038 accuracy: 0.986\n",
      "iter 039 accuracy: 0.986\n",
      "iter 040 accuracy: 0.9855\n",
      "iter 041 accuracy: 0.9865\n",
      "iter 042 accuracy: 0.9857\n",
      "iter 043 accuracy: 0.9862\n",
      "iter 044 accuracy: 0.9859\n",
      "iter 045 accuracy: 0.9873\n",
      "iter 046 accuracy: 0.9856\n",
      "iter 047 accuracy: 0.988\n",
      "iter 048 accuracy: 0.9878\n",
      "iter 049 accuracy: 0.987\n",
      "iter 050 accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "trX, teX, trY, teY = mnist(onehot=True)\n",
    "\n",
    "for i in range(50):\n",
    "    for start, end in zip(range(0, len(trX), 128), range(128, len(trX), 128)):\n",
    "        cost = train(trX[start:end], trY[start:end])\n",
    "    print(\"iter {:03d} accuracy:\".format(i + 1), np.mean(np.argmax(teY, axis=1) == predict(teX)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清理文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "os.remove(\"download_mnist.py\")\n",
    "os.remove(\"load.py\")\n",
    "shutil.rmtree(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano.tensor.nnet import conv2d\n",
    "from theano.tensor.signal import pool\n",
    "\n",
    "trX, teX, trY, teY = mnist(onehot=True)\n",
    "\n",
    "trX = trX.reshape(-1, 1, 28, 28)\n",
    "teX = teX.reshape(-1, 1, 28, 28)\n",
    "\n",
    "def model(X, w, w2, w3, w4, p_drop_conv, p_drop_hidden):\n",
    "    \n",
    "    # X:  128 * 1 * 28 * 28\n",
    "    # w:  32 * 1 * 3 * 3\n",
    "    # full mode\n",
    "    # l1a: 128 * 32 * (28 + 3 - 1) * (28 + 3 - 1)\n",
    "    l1a = rectify(conv2d(X, w, border_mode='full'))\n",
    "    # l1a: 128 * 32 * 30 * 30\n",
    "    # ignore_border False\n",
    "    # l1:  128 * 32 * (30 / 2) * (30 / 2)\n",
    "    l1 = pool.pool_2d(l1a, (2, 2), ignore_border=False)\n",
    "    l1 = dropout(l1, p_drop_conv)\n",
    "\n",
    "    # l1:  128 * 32 * 15 * 15\n",
    "    # w2:  64 * 32 * 3 * 3\n",
    "    # valid mode\n",
    "    # l2a: 128 * 64 * (15 - 3 + 1) * (15 - 3 + 1)\n",
    "    l2a = rectify(conv2d(l1, w2))    \n",
    "    # l2a: 128 * 64 * 13 * 13\n",
    "    # l2:  128 * 64 * (13 / 2 + 1) * (13 / 2 + 1)\n",
    "    l2 = pool.pool_2d(l2a, (2, 2), ignore_border=False)\n",
    "    l2 = dropout(l2, p_drop_conv)\n",
    "\n",
    "    # l2:  128 * 64 * 7 * 7\n",
    "    # w3:  128 * 64 * 3 * 3\n",
    "    # l3a: 128 * 128 * (7 - 3 + 1) * (7 - 3 + 1)\n",
    "    l3a = rectify(conv2d(l2, w3))\n",
    "    # l3a: 128 * 128 * 5 * 5\n",
    "    # l3b: 128 * 128 * (5 / 2 + 1) * (5 / 2 + 1)\n",
    "    l3b = pool.pool_2d(l3a, (2, 2), ignore_border=False)    \n",
    "    # l3b: 128 * 128 * 3 * 3\n",
    "    # l3:  128 * (128 * 3 * 3)\n",
    "    l3 = T.flatten(l3b, outdim=2)\n",
    "    l3 = dropout(l3, p_drop_conv)\n",
    "    \n",
    "    # l3: 128 * (128 * 3 * 3)\n",
    "    # w4: (128 * 3 * 3) * 625\n",
    "    # l4: 128 * 625\n",
    "    l4 = rectify(T.dot(l3, w4))\n",
    "    l4 = dropout(l4, p_drop_hidden)\n",
    "\n",
    "    # l5:  128 * 625\n",
    "    # w5:  625 * 10\n",
    "    # pyx: 128 * 10\n",
    "    pyx = softmax(T.dot(l4, w_o))\n",
    "    return l1, l2, l3, l4, pyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = T.ftensor4()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "w = init_weights((32, 1, 3, 3))\n",
    "w2 = init_weights((64, 32, 3, 3))\n",
    "w3 = init_weights((128, 64, 3, 3))\n",
    "w4 = init_weights((128 * 3 * 3, 625))\n",
    "w_o = init_weights((625, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theano Examples\n"
     ]
    }
   ],
   "source": [
    "print(\"Theano Examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
